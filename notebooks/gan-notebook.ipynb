{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T16:33:13.375907Z",
     "start_time": "2019-03-28T16:33:12.229143Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow.keras.backend as K\n",
    "from glob import glob\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL.ImageOps import invert\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session \n",
    "config = tf.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True \n",
    "# dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True # to log device placement (on which device the operation ran) \n",
    "# (nothing gets printed in Jupyter, only if you run it standalone) \n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess) # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T16:33:18.286770Z",
     "start_time": "2019-03-28T16:33:13.377065Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.pyenv/versions/gpr-gym/lib/python3.6/site-packages/keras_preprocessing/image/utils.py:98: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1677,)\n",
      "(1677, 256, 256, 1)\n",
      "(609, 256, 256, 1)\n",
      "(546, 256, 256, 1)\n",
      "(522, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "concrete_paths = glob('../train-set/normal/post/*_concrete_*')\n",
    "metallic_paths = glob('../train-set/normal/post/*_pec_*')\n",
    "plastic_paths = glob('../train-set/normal/post/*_pvc_*')\n",
    "real_path = glob('/home/will/data/*.png')\n",
    "\n",
    "def load_img(path):\n",
    "    img = image.load_img(path, grayscale=True, target_size=(256,256), interpolation='hamming')\n",
    "    #img = invert(img)\n",
    "    return image.img_to_array(img)\n",
    "\n",
    "concrete_scans = np.array([load_img(path) for path in concrete_paths])\n",
    "metallic_scans = np.array([load_img(path) for path in metallic_paths])\n",
    "plastic_scans = np.array([load_img(path) for path in plastic_paths])\n",
    "\n",
    "concrete_labels = np.zeros((len(concrete_scans),))\n",
    "metallic_labels = np.ones((len(metallic_scans),))\n",
    "plastic_labels = np.ones((len(plastic_scans),)) * 2\n",
    "\n",
    "y = np.concatenate([concrete_labels, metallic_labels, plastic_labels]).astype(np.int32)\n",
    "a_scans = np.concatenate([concrete_scans, metallic_scans, plastic_scans])\n",
    "\n",
    "print(y.shape)\n",
    "print(a_scans.shape)\n",
    "\n",
    "print(concrete_scans.shape)\n",
    "print(metallic_scans.shape)\n",
    "print(plastic_scans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T16:33:18.322895Z",
     "start_time": "2019-03-28T16:33:18.288297Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers.merge import _Merge, multiply\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Embedding\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from functools import partial\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "GRADIENT_PENALTY_WEIGHT = 10 # As per the paper\n",
    "\n",
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((32, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "\n",
    "class ACWGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 256\n",
    "        self.img_cols = 256\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.num_classes = 3\n",
    "        self.latent_dim = 100\n",
    "        self.losslog = []\n",
    "        \n",
    "\n",
    "        self.n_critic = 5\n",
    "        #optimizer = RMSprop(lr=0.00005)\n",
    "        optimizer = Adam(0.0003, 0.5)\n",
    "        # Build the generator and critic\n",
    "        self.generator = self.build_generator()\n",
    "        self.critic = self.build_critic()\n",
    "\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #       for the Critic\n",
    "        #-------------------------------\n",
    "\n",
    "        # Freeze generator's layers while training critic\n",
    "        self.generator.trainable = False\n",
    "\n",
    "        # Image input (real sample)\n",
    "        real_img = Input(shape=self.img_shape)\n",
    "\n",
    "        # Noise input\n",
    "        z_disc = Input(shape=(self.latent_dim,))\n",
    "        \n",
    "        # Generate image based of noise (fake sample) and add label to the input \n",
    "        label = Input(shape=(1,))\n",
    "        fake_img = self.generator([z_disc, label])\n",
    "\n",
    "        # Discriminator determines validity of the real and fake images\n",
    "        fake = self.critic(fake_img)\n",
    "        valid = self.critic(real_img)\n",
    "\n",
    "        # Construct weighted average between real and fake images\n",
    "        averaged_samples = RandomWeightedAverage()([real_img, fake_img])\n",
    "        \n",
    "        # Determine validity of weighted sample\n",
    "        validity_interpolated = self.critic(averaged_samples)\n",
    "\n",
    "        # Use Python partial to provide loss function with additional\n",
    "        # 'averaged_samples' argument\n",
    "        partial_gp_loss = partial(self.gradient_penalty_loss,\n",
    "                          averaged_samples=averaged_samples)\n",
    "        # Functions need names or Keras will throw an error\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty'\n",
    "\n",
    "        self.critic_model = Model(inputs=[real_img, label, z_disc],\n",
    "                                  outputs=[valid, fake, validity_interpolated])\n",
    "        self.critic_model.compile(loss=[self.wasserstein_loss,\n",
    "                                        self.wasserstein_loss,\n",
    "                                        partial_gp_loss],\n",
    "                                        optimizer=optimizer,\n",
    "                                        loss_weights=[1, 1, 10])\n",
    "        \n",
    "        self.aux_model = self.build_classifier()\n",
    "        \n",
    "        real_pred = self.aux_model(real_img)\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #         for Generator\n",
    "        #-------------------------------\n",
    "\n",
    "        # For the generator we freeze the critic's layers\n",
    "        self.critic.trainable = False\n",
    "        self.generator.trainable = True\n",
    "\n",
    "        # Sampled noise for input to generator\n",
    "        z_gen = Input(shape=(100,))\n",
    "        # add label to the input\n",
    "        #label = Input(shape=(1,))\n",
    "        # Generate images based of noise\n",
    "        img = self.generator([z_gen, label])\n",
    "        # Discriminator determines validity\n",
    "        valid = self.critic(img)\n",
    "        #gen_pred = self.aux_model(img)\n",
    "        # Defines generator model\n",
    "        self.generator_model = Model([z_gen, label], [valid])\n",
    "        self.generator_model.compile(loss=self.wasserstein_loss,\n",
    "                                     optimizer=optimizer)\n",
    "        \n",
    "        \n",
    "        self.aux_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                               optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        \n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "    \n",
    "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
    "        \"\"\"\n",
    "        Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "        \"\"\"\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        # compute the euclidean norm by squaring ...\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        #   ... summing over the rows ...\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        #   ... and sqrt\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "        # return the mean as loss over all the batch samples\n",
    "        return K.mean(gradient_penalty)\n",
    "\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "        out = Dense(128 * 8 * 8,\n",
    "                        activation=\"relu\",\n",
    "                        input_dim=self.latent_dim)(noise)\n",
    "        out = Reshape((8, 8, 128))(out)\n",
    "        \n",
    "        out = BatchNormalization(momentum=0.8)(out)\n",
    "        out = UpSampling2D()(out)\n",
    "        out = Conv2D(256, kernel_size=5, padding=\"same\")(out)\n",
    "        out = Activation(\"relu\")(out)\n",
    "        \n",
    "        out = BatchNormalization(momentum=0.8)(out)\n",
    "        out = UpSampling2D()(out)\n",
    "        model.add(Conv2D(128, kernel_size=5, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=5, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(32, kernel_size=5, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(16, kernel_size=5, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding='same'))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        #model.summary()\n",
    "\n",
    "        \n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, 100)(label))\n",
    "\n",
    "        model_input = multiply([noise, label_embedding])\n",
    "        img = model(model_input)\n",
    "\n",
    "        gen = Model([noise, label], img)\n",
    "        print(gen.summary())\n",
    "        return gen\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(16, kernel_size=5, strides=2, padding=\"same\", input_shape=self.img_shape))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(16*2, kernel_size=5, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(16*4, kernel_size=5, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(16*8, kernel_size=5, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(16*16, kernel_size=5, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        #model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        \n",
    "        features = model(img)\n",
    "        # Determine validity and label of the image\n",
    "        validity = Dense(1, activation=None)(features)\n",
    "        label_prob = Dense(self.num_classes, activation=\"softmax\")(features)\n",
    "\n",
    "        model = Model(img, validity)\n",
    "        print(model.summary())\n",
    "        return model\n",
    "    \n",
    "    def build_classifier(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(16, kernel_size=5, strides=2, padding=\"same\", input_shape=self.img_shape))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        model.add(Conv2D(32, kernel_size=5, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "        img = Input(shape=self.img_shape)\n",
    "        \n",
    "        label = model(img)\n",
    "        \n",
    "        return Model(img, label)\n",
    "\n",
    "    def train(self, epochs, batch_size=16, sample_interval=50):\n",
    "        \n",
    "        aux_checkpoint = ModelCheckpoint('checkpoints/aux_model.h5',\n",
    "                                         save_best_only=True)\n",
    "        generator_checkpoint = ModelCheckpoint('checkpoints/generator_freq.h5',\n",
    "                                               save_best_only=True,\n",
    "                                               save_weights_only=True)\n",
    "        disc_checkpoint = ModelCheckpoint('checkpoints/disc_freq.h5',\n",
    "                                          save_best_only=True)\n",
    "        # Load the dataset\n",
    "        X_train, X_test, y_train, y_test = train_test_split(a_scans, y, test_size=0.3)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Configure inputs\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "        y_test = y_test.reshape(-1, 1)\n",
    "        \n",
    "        np.save('X_test.npy', X_test)\n",
    "        np.save('y_test.npy', y_test)\n",
    "\n",
    "         # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake =  np.ones((batch_size, 1))\n",
    "        dummy = np.zeros((batch_size, 1)) # Dummy gt for gradient penalty\n",
    "        \n",
    "        test_loss = []\n",
    "            \n",
    "        for epoch in tqdm(range(epochs+1)):\n",
    "            \n",
    "            for _ in range(self.n_critic):\n",
    "                sampled_labels = np.random.randint(0, self.num_classes, batch_size).reshape(-1, 1)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "                \n",
    "                # Select a random batch of images\n",
    "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                test_idx = np.random.randint(0, X_test.shape[0], batch_size)\n",
    "                imgs, labels = X_train[idx], y_train[idx]\n",
    "                test_imgs, test_labels = X_test[test_idx], y_test[test_idx]\n",
    "                \n",
    "                \n",
    "                # Sample generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                # Train the critic\n",
    "                d_loss = self.critic_model.fit([imgs, labels, noise],\n",
    "                                               [valid, fake, dummy],\n",
    "                                               batch_size=batch_size,\n",
    "                                               validation_data=[[test_imgs, test_labels, noise],\n",
    "                                                                [valid, fake, dummy]],\n",
    "                                               verbose=0,\n",
    "                                               callbacks=[disc_checkpoint])\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "            #aux_loss = self.aux_model.fit(imgs, labels, \n",
    "             #                             batch_size=batch_size,\n",
    "              #                            validation_data=[test_imgs,\n",
    "               #                                            test_labels],\n",
    "                #                          verbose=0,\n",
    "                 #                         callbacks=[aux_checkpoint])\n",
    "            g_loss = self.generator_model.fit([noise, labels],\n",
    "                                              [valid], \n",
    "                                              batch_size=batch_size,\n",
    "                                              validation_data=[[noise, test_labels],\n",
    "                                                               [valid]],\n",
    "                                              verbose=0,\n",
    "                                              callbacks=[generator_checkpoint])\n",
    "            \n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "                self.generator.save_weights(f'generator_normal_{epoch}')\n",
    "\n",
    "            with open('loss_same_labels.log', 'w') as f:\n",
    "                f.writelines('d_loss, g_loss\\n')\n",
    "                for each in self.losslog:\n",
    "                    f.writelines('%s, %s\\n'%(each[0], each[1]))\n",
    "                    \n",
    "        \n",
    "                        \n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 4, 4\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        sampled_labels = np.array([np.random.randint(0, 3, 1) for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise, sampled_labels])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "    def save_model(self):\n",
    "\n",
    "        def save(model, model_name):\n",
    "            model_path = \"saved_model/%s.json\" % model_name\n",
    "            weights_path = \"saved_model/%s_weights.hdf5\" % model_name\n",
    "            options = {\"file_arch\": model_path,\n",
    "                        \"file_weight\": weights_path}\n",
    "            json_string = model.to_json()\n",
    "            open(options['file_arch'], 'w').write(json_string)\n",
    "            model.save_weights(options['file_weight'])\n",
    "\n",
    "        save(self.generator, \"generator\")\n",
    "        save(self.critic, \"discriminator\")\n",
    "        \n",
    "    def plot_loss(self, gen_loss, disc_loss):\n",
    "        gen_loss = np.array(gen_loss)\n",
    "        disc_loss = np.array(disc_loss)\n",
    "        plt.plot(gen_loss)\n",
    "        plt.savefig('saved_model/gen_loss.png')\n",
    "        plt.plot(disc_loss)\n",
    "        plt.savefig('saved_model/disc_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T16:33:31.680254Z",
     "start_time": "2019-03-28T16:33:18.324065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/.pyenv/versions/gpr-gym/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 100)       300         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 100)          0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 100)          0           input_1[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 256, 256, 1)  2737729     multiply_1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,738,029\n",
      "Trainable params: 2,736,781\n",
      "Non-trainable params: 1,248\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 256, 256, 1)       0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 16384)             1088896   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 16385     \n",
      "=================================================================\n",
      "Total params: 1,105,281\n",
      "Trainable params: 1,105,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50001 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/will/.pyenv/versions/gpr-gym/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.pyenv/versions/gpr-gym/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-566a0d6c720a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0macgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mACWGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0macgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-1344e03730ec>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    292\u001b[0m                                                                 [valid, fake, dummy]],\n\u001b[1;32m    293\u001b[0m                                                \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                                                callbacks=[disc_checkpoint])\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/gpr-gym/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.pyenv/versions/gpr-gym/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/gpr-gym/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/gpr-gym/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/gpr-gym/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/gpr-gym/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/gpr-gym/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/gpr-gym/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, op, message)\u001b[0m\n\u001b[1;32m    339\u001b[0m   \"\"\"\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m     \u001b[0;34m\"\"\"Creates a `ResourceExhaustedError`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     super(ResourceExhaustedError, self).__init__(node_def, op, message,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acgan = ACWGAN()\n",
    "\n",
    "acgan.train(epochs=50000, batch_size=32, sample_interval=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpr-gym",
   "language": "python",
   "name": "gpr-gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
